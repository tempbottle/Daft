name: Build a specific daft commit and store it in AWS S3

on:
  workflow_call:
    secrets:
      aws_role_arn:
        description: The ARN of the AWS role to assume
        required: true
    inputs:
      commit:
        type: string
        description: The commit hash to build
        required: true
      machine_type:
        type: string
        description: The machine type to use for the build
        required: true
    outputs:
      wheel:
        description: The wheel file that was built
        value: ${{ jobs.build_and_upload.outputs.wheel }}

jobs:
  build-commit:
    runs-on: ${{ inputs.machine_type }}
    timeout-minutes: 15 # Remove for ssh debugging
    permissions:
      id-token: write
      contents: read
    outputs:
      wheel: ${{ steps.build_and_upload.outputs.wheel }}
    steps:
    - uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-region: us-west-2
        role-to-assume: ${{ secrets.aws_role_arn }}
        role-session-name: daft-performance-comparisons-build
    - uses: actions/checkout@v4
      with:
        ref: ${{ inputs.commit }}
    - uses: ./.github/actions/install
    - uses: actions/cache@v3
      with:
        path: ~/target/debug
        key: ${{ runner.os }}-cargo-deps-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-deps-
    - id: build_and_upload
      run: |
        # Build wheel
        export CARGO_TARGET_DIR=~/target
        uv v
        source .venv/bin/activate
        uv pip install pip
        uv pip install maturin
        maturin build

        # Upload wheel
        # (there should only be one output wheel in this directory)
        for file in ~/target/wheels/*.whl; do
          aws s3 cp $file s3://github-actions-artifacts-bucket/builds/${{ github.sha }}/${{ inputs.commit }}/ --acl public-read --no-progress;
          file_basename=$(basename $file)
          echo "wheel=$file_basename" >> $GITHUB_OUTPUT
        done
